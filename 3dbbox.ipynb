{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 11685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decord import VideoLoader, cpu\n",
    "import decord\n",
    "frames_per_clip = 16\n",
    "frame_step = 4\n",
    "video_paths = [\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/compressed_objects/segmentation_videos/000001/input.mp4\",\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/compressed_objects/segmentation_videos/000002/input.mp4\",\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/compressed_objects/segmentation_videos/000003/input.mp4\",\n",
    "]\n",
    "K_jsons = [\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/000001/scene_camera.json\",\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/000002/scene_camera.json\",\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/000003/scene_camera.json\"\n",
    "]\n",
    "gt_jsons = [\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/000001/scene_gt.json\",\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/000002/scene_gt.json\",\n",
    "    \"/home/vgl/emir/datasets/tudl/train_real/000003/scene_gt.json\"\n",
    "]\n",
    "models = [\n",
    "    \"/home/vgl/emir/datasets/tudl/tudl_models/models/obj_000001.ply\",\n",
    "    \"/home/vgl/emir/datasets/tudl/tudl_models/models/obj_000002.ply\",\n",
    "    \"/home/vgl/emir/datasets/tudl/tudl_models/models/obj_000003.ply\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decord.bridge.set_bridge('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from utils import Video3DBBoxDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_3d_bbox_on_frame(frame, bbox):\n",
    "    \"\"\"\n",
    "    Visualize the 3D bounding box on a single frame.\n",
    "    \n",
    "    Parameters:\n",
    "    - frame: numpy array of shape (H, W, 3)\n",
    "    - bbox: dictionary with keys 'center', 'dimensions', 'rotation_matrix', 'K'\n",
    "    \n",
    "    Returns:\n",
    "    - frame_with_bbox: frame with the 3D bounding box drawn on it\n",
    "    \"\"\"\n",
    "    center = bbox['center']  # [x, y, z]\n",
    "    dimensions = bbox['dimensions']  # [width, height, depth]\n",
    "    rotation_matrix = bbox['rotation_matrix']  # [3, 3]\n",
    "    K = bbox['K']  # [3, 3]\n",
    "\n",
    "    # Half dimensions\n",
    "    dx = dimensions[0] / 2\n",
    "    dy = dimensions[1] / 2\n",
    "    dz = dimensions[2] / 2\n",
    "\n",
    "    # Define the 8 corners in local coordinates\n",
    "    corners_local = np.array([\n",
    "        [-dx, -dy, -dz],\n",
    "        [-dx, -dy, dz],\n",
    "        [-dx, dy, -dz],\n",
    "        [-dx, dy, dz],\n",
    "        [dx, -dy, -dz],\n",
    "        [dx, -dy, dz],\n",
    "        [dx, dy, -dz],\n",
    "        [dx, dy, dz],\n",
    "    ])  # Shape: (8, 3)\n",
    "\n",
    "    corners_world = (rotation_matrix @ corners_local.T).T + center.reshape(1, 3)  # Shape: (8, 3)\n",
    "    corners_homogeneous = corners_world.T  # Shape: (3, 8)\n",
    "    corners_2d_hom = K @ corners_homogeneous  # Shape: (3, 8)\n",
    "    corners_2d = (corners_2d_hom[:2, :] / corners_2d_hom[2, :]).T  # Shape: (8, 2)\n",
    "\n",
    "    # Draw the bounding box on the frame\n",
    "    lines = [\n",
    "        [0, 1], [1, 3], [3, 2], [2, 0],  # Bottom face\n",
    "        [4, 5], [5, 7], [7, 6], [6, 4],  # Top face\n",
    "        [0, 4], [1, 5], [2, 6], [3, 7]   # Vertical edges\n",
    "    ]\n",
    "\n",
    "    frame_with_bbox = np.array(frame).copy()\n",
    "    for start, end in lines:\n",
    "        pt1 = tuple(corners_2d[start].astype(int))\n",
    "        pt2 = tuple(corners_2d[end].astype(int))\n",
    "        # Ensure points are within image boundaries\n",
    "        h, w = frame.shape[:2]\n",
    "        pt1 = (np.clip(pt1[0], 0, w - 1), np.clip(pt1[1], 0, h - 1))\n",
    "        pt2 = (np.clip(pt2[0], 0, w - 1), np.clip(pt2[1], 0, h - 1))\n",
    "        cv2.line(frame_with_bbox, pt1, pt2, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    return frame_with_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = Video3DBBoxDataset(\n",
    "    video_paths=video_paths,\n",
    "    models=models,\n",
    "    K_jsons=K_jsons,\n",
    "    gt_jsons=gt_jsons,\n",
    "    frames_per_clip=frames_per_clip,\n",
    "    frame_step=frame_step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = cv2.VideoWriter(\"./bbox_vis.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_502558/1056504729.py:46: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  frame_with_bbox = np.array(frame).copy()\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vd)):\n",
    "    x, bbox = vd[i]\n",
    "    for j in range(frames_per_clip):\n",
    "        frame_with_bbox = visualize_3d_bbox_on_frame(x[j], bbox[j])\n",
    "        vr.write(frame_with_bbox)\n",
    "vr.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emirenv_samv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
